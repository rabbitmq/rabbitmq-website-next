<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta content="73d8ba46-8c12-43f6-8c22-24aa21b8d93d" name="onetrust-data-domain" /><meta content="https://tags.tiqcdn.com/utag/vmware/microsites-privacy/prod/utag.js" name="microsites-utag" /><script src="https://d1fto35gcfffzn.cloudfront.net/assets/jquery-1.11.2.min.js"></script><script src="//www.vmware.com/files/templates/inc/utag_data.js"></script><script src="//tags.tiqcdn.com/utag/vmware/microsites-privacy/prod/utag.sync.js"></script><script>function OptanonWrapper() { { window.dataLayer.push({ event: 'OneTrustGroupsUpdated' }); } }</script><script src="/js/gtm.js"></script><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><meta name="googlebot" content="NOODP" /><meta name="google-site-verification" content="nSYeDgyKM9mw5CWcZuD0xu7iSWXlJijAlg9rcxVOYf4" /><meta name="google-site-verification" content="6UEaC3SWhpGQvqRnSJIEm2swxXpM5Adn4dxZhFsNdw0" /><meta content="width=device-width, initial-scale=1.0, maximum-scale=1, minimum-scale=1, user-scalable=no" id="viewport" name="viewport" /><link href="https://fonts.googleapis.com/css?family=Raleway:400,500,600,700" rel="stylesheet" /><link rel="stylesheet" href="/css/rabbit.css" type="text/css" /><link rel="stylesheet" href="/css/highlightjs_style.css" type="text/css" /><link rel="stylesheet" href="/css/rabbit-next.css" type="text/css" /><!--[if IE 6]>
      <link rel="stylesheet" href="/css/rabbit-ie6.css" type="text/css" />
      <![endif]--><link rel="icon" type="/image/vnd.microsoft.icon" href="/favicon.ico" /><link rel="stylesheet" href="/css/tutorial.css" type="text/css" /><script async="true" type="text/javascript" src="/js/site.js"></script><title> Streams 
 â€” RabbitMQ</title></head>
  <body id="streams"><div id="outerContainer"><div class="container"><div class="rabbit-logo"><a href="/"><img src="/img/logo-rabbitmq.svg" alt="RabbitMQ" /></a></div><a class="btn menubtn" onclick="showHide()">Menu <img src="/img/carrot-down-white.svg" /></a><div class="mobilemenuicon" onclick="showHide()"><img src="/img/mobile-menu-icon.svg" /></div><div id="nav"><ul id="mainNav"><li><a href="/#features">Features</a></li><li><a href="/#getstarted">Get Started</a></li><li><a href="/#support">Support</a></li><li><a href="/#community">Community</a></li><li><a href="/documentation.html">Docs</a></li></ul></div></div><div class="nav-separator"></div><div id="innerContainer" class="container"><div id="left-content"><h1> Streams 
</h1>


<h2><a id="overview" class="anchor" href="#overview">Overview</a></h2>
<p>Streams are a new persistent and replicated data structure <em>in RabbitMQ 3.9</em> which models
an append-only log with non-destructive consumer semantics.
They can be used via a RabbitMQ client library as if  it was a queue or through a
<a href="https://github.com/rabbitmq/rabbitmq-server/blob/v3.10.x/deps/rabbitmq_stream/docs/PROTOCOL.adoc">dedicated binary protocol</a>
plugin and associated client(s). The latter option is recommended as it
provides access to all stream-specific features and offers best possible throughput (performance).</p>
<p>This page covers the concepts of streams, their usage, and
their administration and maintenance operations. Please visit the <a href="./stream.html">Stream plugin</a>
page to learn more about the usage of streams with the binary RabbitMQ Stream protocol.</p>
<h3><a id="use-cases" class="anchor" href="#use-cases">Use Cases</a></h3>
<p>Streams were developed to initially cover 4 messaging use-cases that
existing queue types either can not provide or provide with downsides:</p>
<ol>
<li>
<p>Large fan-outs</p>
<p>When wanting to deliver the same message to multiple subscribers users currently
have to bind a dedicated queue for each consumer. If the number of consumers is
large this becomes potentially inefficient, especially when wanting persistence
and/or replication. Streams will allow any number of consumers to consume
the same messages from the same queue in a non-destructive manner, negating the need
to bind multiple queues. Stream consumers will also be able to read from replicas
allowing read load to be spread across the cluster.</p>
</li>
<li>
<p>Replay / Time-travelling</p>
<p>As all current RabbitMQ queue types have destructive consume behaviour, i.e. messages
are deleted from the queue when a consumer is finished with them, it is not
possible to re-read messages that have been consumed. Streams will allow
consumers to attach at any point in the log and read from there.</p>
</li>
<li>
<p>Throughput Performance</p>
<p>No persistent queue types are able to deliver throughput that can compete with
any of the existing log based messaging systems. Streams have been designed
with performance as a major goal.</p>
</li>
<li>
<p>Large logs</p>
<p>Most RabbitMQ queues are designed to converge towards the empty state and are
optimised as such and can perform worse when there are millions of messages on a
given queue. Streams are designed to store larger amounts of data in an
efficient manner with minimal in-memory overhead.</p>
</li>
</ol>
<h2><a id="usage" class="anchor" href="#usage">Usage</a></h2>
<p>An AMQP 0.9.1 client library that can specify <a href="./queues.html#optional-arguments">optional queue and consumer arguments</a>
will be able to use streams as regular AMQP 0.9.1 queues.</p>
<p>Just like queues, streams have to be declared first.</p>
<h3><a id="declaring" class="anchor" href="#declaring">Declaring</a></h3>
<p>To declare a stream, set the <span class="code ">x-queue-type</span> queue argument to <span class="code ">stream</span>
(the default is <span class="code ">classic</span>). This argument must be provided by a client
at declaration time; it cannot be set or changed using a <a href="./parameters.html#policies">policy</a>.
This is because policy definition or applicable policy can be changed dynamically but
queue type cannot. It must be specified at the time of declaration.</p>
<p>The following snippet shows how to create a stream with the <a href="./api-guide.html">AMQP 0.9.1 Java client</a>:</p>
<pre class="lang-java">
ConnectionFactory factory = new ConnectionFactory();
Connection connection = factory.newConnection();
Channel channel = connection.createChannel();
channel.queueDeclare(
  "my-stream",
  true,         // durable
  false, false, // not exclusive, not auto-delete
  Collections.singletonMap("x-queue-type", "stream")
);
</pre>

<p>Declaring a queue with an <span class="code ">x-queue-type</span> argument set to <span class="code ">stream</span> will create a stream
with a replica on each configured RabbitMQ node. Streams are quorum systems
so uneven cluster sizes is strongly recommended.</p>
<p>A stream remains an AMQP 0.9.1 queue, so it can be bound to any exchange after its creation,
just as any other RabbitMQ queue.</p>
<p>If declaring using <a href="./management.html">management UI</a>, the <span class="code ">stream</span> type must be specified using
the queue type drop down menu.</p>
<p>Streams support 3 additional <a href="./queues.html#optional-arguments">queue arguments</a>
that are best configured using a <a href="./parameters.html#policies">policy</a></p>
<ul>
<li><span class="code ">x-max-length-bytes</span></li>
</ul>
<p>Sets the maximum size of the stream in bytes. See <a href="#retention">retention</a>. Default: not set.</p>
<ul>
<li><span class="code ">x-max-age</span></li>
</ul>
<p>Sets the maximum age of the stream. See <a href="#retention">retention</a>. Default: not set.</p>
<ul>
<li><span class="code ">x-stream-max-segment-size-bytes</span></li>
</ul>
<p>Unit: bytes. A stream is divided up into fixed size segment files on disk.
This setting controls the size of these.
Default: (500000000 bytes).</p>
<p>The following snippet shows how to set the maximum size of a stream to 20 GB, with
segment files of 100 MB:</p>
<pre class="lang-java">
Map&lt;String, Object&gt; arguments = new HashMap&lt;&gt;();
arguments.put("x-queue-type", "stream");
arguments.put("x-max-length-bytes", 20_000_000_000); // maximum stream size: 20 GB
arguments.put("x-stream-max-segment-size-bytes", 100_000_000); // size of segment files: 100 MB
channel.queueDeclare(
  "my-stream",
  true,         // durable
  false, false, // not exclusive, not auto-delete
  arguments
);
</pre>

<h3>Client Operations</h3>
<h4><a id="consuming" class="anchor" href="#consuming">Consuming</a></h4>
<p>As streams never delete any messages, any consumer can start reading/consuming
from any point in the log. This is controlled by the <span class="code ">x-stream-offset</span> consumer argument.
If it is unspecified the consumer will start reading from the next offset written
to the log after the consumer starts. The following values are supported:</p>
<ul>
<li><span class="code ">first</span> - start from the first available message in the log</li>
<li><span class="code ">last</span> - this starts reading from the last written "chunk" of messages <em>(a chunk
 is the storage and transportation unit used in streams, put simply it is a batch
 of messages made of several to a few thousands of messages, depending on the ingress)</em></li>
<li><span class="code ">next</span> - same as not specifying any offset</li>
<li>Offset - a numerical value specifying an exact offset to attach to the log at. If
this offset does not exist it will clamp to either the start or end of the log respectively.</li>
<li>Timestamp - a timestamp value specifying the point in time to attach to the log at. It will clamp to the closest offset, if the timestamp is out of range for the stream it will clamp either the start or end of the log respectively. With AMQP 0.9.1, the timestamp used is POSIX
 time with an accuracy of one second, that is the number of seconds since 00:00:00 UTC, 1970-01-01.</li>
<li>Interval - a string value specifying the time interval relative to current time to attach the log at. Uses the same specification as <span class="code ">x-max-age</span> (see <a href="#retention">Retention</a>)</li>
</ul>
<p>The following snippet shows how to use the <span class="code ">first</span> offset specification:</p>
<pre class="lang-java">
channel.basicQos(100); // QoS must be specified
channel.basicConsume(
  "my-stream",
  false,
  Collections.singletonMap("x-stream-offset", "first"), // "first" offset specification
  (consumerTag, message) -&gt; {
    // message processing
    // ...
   channel.basicAck(message.getEnvelope().getDeliveryTag(), false); // ack is required
  },
  consumerTag -&gt; { });
</pre>

<p>The following snippet shows how to specify a specific offset to consume from:</p>
<pre class="lang-java">
channel.basicQos(100); // QoS must be specified
channel.basicConsume(
  "my-stream",
  false,
  Collections.singletonMap("x-stream-offset", 5000), // offset value
  (consumerTag, message) -&gt; {
    // message processing
    // ...
   channel.basicAck(message.getEnvelope().getDeliveryTag(), false); // ack is required
  },
  consumerTag -&gt; { });
</pre>

<p>The following snippet shows how to specify a specific timestamp to consume from:</p>
<pre class="lang-java">
// an hour ago
Date timestamp = new Date(System.currentTimeMillis() - 60 * 60 * 1_000)
channel.basicQos(100); // QoS must be specified
channel.basicConsume(
  "my-stream",
  false,
  Collections.singletonMap("x-stream-offset", timestamp), // timestamp offset
  (consumerTag, message) -&gt; {
    // message processing
    // ...
   channel.basicAck(message.getEnvelope().getDeliveryTag(), false); // ack is required
  },
  consumerTag -&gt; { });
</pre>

<h4>Other</h4>
<p>The following operations can be used in a similar way to classic and quorum queues
but some have some queue specific behaviour.</p>
<ul>
<li><a href="#declaring">Declaration</a></li>
<li>Queue deletion</li>
<li><a href="./confirms.html#publisher-confirms">Publisher confirms</a></li>
<li><a href="./consumers.html">Consumption</a> (subscription): consumption requires QoS
 prefetch to be set. The acks works as a credit mechanism to advance the current
 offset of the consumer.</li>
<li>Setting <a href="#global-qos">QoS prefetch</a> for consumers</li>
<li><a href="./confirms.html">Consumer acknowledgements</a> (keep <a href="#global-qos">QoS Prefetch Limitations</a> in mind)</li>
<li>Cancellation of consumers</li>
</ul>
<h2><a id="feature-comparison" class="anchor" href="#feature-comparison">Feature Comparison with Regular Queues</a></h2>
<p>Streams are not really queues in the traditional sense and thus do not
align very closely with AMQP 0.9.1 queue semantics. Many features that other queue types
support are not supported and will never be due to the nature of the queue type.</p>
<p>An AMQP 0.9.1 client library that can use <a href="./queues.html">regular queues</a> will be able to use streams
as long as it uses consumer acknowledgements.</p>
<p>Many features will never be supported by streams due to their non-destructive
read semantics.</p>
<h3><a id="feature-matrix" class="anchor" href="#feature-matrix">Feature Matrix</a></h3>
<table>
<thead>
<tr>
<th align="left">Feature</th>
<th align="left">Classic</th>
<th>Stream</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left"><a href="./queues.html">Non-durable queues</a></td>
<td align="left">yes</td>
<td>no</td>
</tr>
<tr>
<td align="left"><a href="./queues.html">Exclusivity</a></td>
<td align="left">yes</td>
<td>no</td>
</tr>
<tr>
<td align="left">Per message persistence</td>
<td align="left">per message</td>
<td>always</td>
</tr>
<tr>
<td align="left">Membership changes</td>
<td align="left">automatic</td>
<td>manual</td>
</tr>
<tr>
<td align="left"><a href="./ttl.html">TTL</a></td>
<td align="left">yes</td>
<td>no (but see <a href="#retention">Retention</a>)</td>
</tr>
<tr>
<td align="left"><a href="./maxlength.html">Queue length limits</a></td>
<td align="left">yes</td>
<td>no (but see <a href="#retention">Retention</a>)</td>
</tr>
<tr>
<td align="left"><a href="./lazy-queues.html">Lazy behaviour</a></td>
<td align="left">yes</td>
<td>inherent</td>
</tr>
<tr>
<td align="left"><a href="./priority.html">Message priority</a></td>
<td align="left">yes</td>
<td>no</td>
</tr>
<tr>
<td align="left"><a href="./consumer-priority.html">Consumer priority</a></td>
<td align="left">yes</td>
<td>no</td>
</tr>
<tr>
<td align="left"><a href="./dlx.html">Dead letter exchanges</a></td>
<td align="left">yes</td>
<td>no</td>
</tr>
<tr>
<td align="left">Adheres to <a href="./parameters.html#policies">policies</a></td>
<td align="left">yes</td>
<td>(see <a href="#retention">Retention</a>)</td>
</tr>
<tr>
<td align="left">Reacts to <a href="./alarms.html">memory alarms</a></td>
<td align="left">yes</td>
<td>no (uses minimal RAM)</td>
</tr>
<tr>
<td align="left">Poison message handling</td>
<td align="left">no</td>
<td>no</td>
</tr>
<tr>
<td align="left">Global <a href="#global-qos">QoS Prefetch</a></td>
<td align="left">yes</td>
<td>no</td>
</tr>
</tbody>
</table>
<h4>Non-durable Queues</h4>
<p>Streams are always durable per their assumed <a href="#use-cases">use cases</a>,
they cannot be <a href="./queues.html#properties">non-durable</a> like regular queues.</p>
<h4>Exclusivity</h4>
<p>Streams are always durable per their assumed <a href="#use-cases">use cases</a>, they cannot be
<a href="./queues.html#exclusive-queues">exclusive</a> like regular queues.
They are not meant to be used as <a href="./queues.html#temporary-queues">temporary queues</a>.</p>
<h4>Lazy Mode</h4>
<p>Streams store all data directly on disk, after a message has been written
it does not use any memory until it is read. Streams are inherently <a href="./lazy-queues.html">lazy</a>, so to speak.</p>
<h4><a id="global-qos" class="anchor" href="#global-qos">Global QoS</a></h4>
<p>Streams do not support global <a href="./confirms.html#channel-qos-prefetch">QoS prefetch</a> where a channel sets a single
prefetch limit for all consumers using that channel. If an attempt
is made to consume from a stream from a channel with global QoS enabled
a channel error will be returned.</p>
<p>Use <a href="./consumer-prefetch.html">per-consumer QoS prefetch</a>, which is the default in several popular clients.</p>
<h2><a id="retention" class="anchor" href="#retention">Data Retention</a></h2>
<p>Streams are implemented as an immutable append-only disk log. This means that
the log will grow indefinitely until the disk runs out. To avoid this undesirable
scenario it is possible to set a retention configuration per stream which will
discard the oldest data in the log based on total log data size and/or age.</p>
<p>There are two parameters that control the retention of a stream. These can be combined.
These are either set at declaration time using a queue argument or as a policy which
can be dynamically updated.</p>
<ul>
<li>
<p><span class="code ">max-age</span>:</p>
<p>valid units: Y, M, D, h, m, s</p>
<p>e.g. <span class="code ">7D</span> for a week</p>
</li>
<li>
<p><span class="code ">max-length-bytes</span>:</p>
<p>the max total size in bytes</p>
</li>
</ul>
<p>NB: retention is evaluated on per segment basis so there is one more parameter
that comes into effect and that is the segment size of the stream. The stream will
always leave at least one segment in place as long as the segment contains at least
one message.
When using broker-provided <a href="#offset-tracking">offset-tracking</a>, offsets for each consumer
are persisted in the stream itself as non-message data.</p>
<h2><a id="performance" class="anchor" href="#performance">Performance Characteristics</a></h2>
<p>As streams persist all data to disks before doing anything it is recommended
to use the fastest disks possible.</p>
<p>Due to the disk I/O-heavy nature of streams, their throughput decreases
as message sizes increase.</p>
<p>Just like quorum queues, streams are also affected by cluster sizes.
The more replicas a stream has, the lower its throughput generally will
be since more work has to be done to replicate data and achieve consensus.</p>
<h3><a id="replication-factor" class="anchor" href="#replication-factor">Controlling the Initial Replication Factor</a></h3>
<p>The <span class="code ">x-initial-cluster-size</span> queue argument controls how many rabbit nodes the initial
stream cluster should span.</p>
<h3><a id="replica-management" class="anchor" href="#replica-management">Managing Stream Replicas</a></h3>
<p>Replicas of a stream are explicitly managed by the operator. When a new node is added
to the cluster, it will host no stream replicas unless the operator explicitly adds it
to a replica set of a stream.</p>
<p>When a node has to be decommissioned (permanently removed from the cluster), it must be explicitly
removed from the replica list of all streams it currently hosts replicas for.</p>
<p>Two <a href="./cli.html">CLI commands</a> are provided to perform the above operations,
<span class="code ">rabbitmq-streams add_replica</span> and <span class="code ">rabbitmq-streams delete_replica</span>:</p>
<pre class="lang-bash">
rabbitmq-streams add_replica [-p &lt;vhost&gt;] &lt;stream-name&gt; &lt;node&gt;
</pre>

<pre class="lang-bash">
rabbitmq-streams delete_replica [-p &lt;vhost&gt;] &lt;stream-name&gt; &lt;node&gt;
</pre>

<p>To successfully add and remove replicas the stream coordinator must be
available in the cluster.</p>
<p>Care needs to be taken not to accidentally make a stream unavailable by losing
the quorum whilst performing maintenance operations that involve membership changes.</p>
<p>Because the stream membership isn't embedded in the stream itself adding a replica
cannot be made entirely safe at the current time. Hence if there at any time is an
out of sync replica another replica cannot be added and an error will be returned.</p>
<p>When replacing a cluster node, it is safer to first add a new node, wait for it
to become in-sync and then de-comission the node it replaces.</p>
<p>The replication status of a stream can be queried using the following command:</p>
<pre class="lang-bash">
rabbitmq-streams stream_status [-p &lt;vhost&gt;] &lt;stream-name&gt;
</pre>

<h2><a id="behaviour" class="anchor" href="#behaviour">Behaviour</a></h2>
<p>Every stream has a primary writer (the leader) and zero or more replicas.</p>
<h3><a id="leader-election" class="anchor" href="#leader-election">Leader Election and Failure Handling</a></h3>
<p>When a new stream is declared, the set of nodes that will host its
replicas is randomly picked, but will always include the node the client that declares the stream is connected to.</p>
<p>Which replica becomes the initial leader is controlled in three ways,
namely, using the <span class="code ">x-queue-leader-locator</span> <a href="queues.html#optional-arguments">optional queue argument</a>, setting the <span class="code ">queue-leader-locator</span>
policy key or by defining the <span class="code ">queue_leader_locator</span>
key in <a href="configure.html#configuration-files">the configuration file</a>. Here are the possible values:</p>
<ul>
<li><span class="code ">client-local</span>: Pick the node the client that declares the stream is connected to. This is the default value.</li>
<li><span class="code ">balanced</span>: If there are overall less than 1000 queues (classic queues, quorum queues, and streams),
 pick the node hosting the minimum number of stream leaders.
 If there are overall more than 1000 queues, pick a random node.</li>
</ul>
<p>A stream requires a quorum of the declared nodes to be available
to function. When a RabbitMQ node hosting a stream's
<em>leader</em> fails or is stopped another node hosting one of that
stream's <em>replica</em> will be elected leader and resume
operations.</p>
<p>Failed and rejoining replicas will re-synchronise ("catch up") with the leader.
Similarly to quorum queues queues, a temporary replica failure
does not require a full re-synchronization from the currently elected leader. Only the delta
will be transferred if a re-joining replica is behind the leader. This "catching up" process
does not affect leader availability.</p>
<p>Replicas must be explicitly added.
When a new replica is <a href="#replica-management">added</a>, it will synchronise the entire stream state
from the leader, similarly to newly added quorum queue replicas.</p>
<h3><a id="quorum-requirements" class="anchor" href="#quorum-requirements">Fault Tolerance and Minimum Number of Replicas Online</a></h3>
<p>Consensus systems can provide certain guarantees with regard to data safety.
These guarantees do mean that certain conditions need to be met before they
become relevant such as requiring a minimum of three cluster nodes to provide
fault tolerance and requiring more than half of members to be available to
work at all.</p>
<p>Failure tolerance characteristics of clusters of various size can be described
in a table:</p>
<table>
<thead>
<tr>
<th align="center">Cluster node count</th>
<th align="center">Tolerated number of node failures</th>
<th align="center">Tolerant to a network partition</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">not applicable</td>
</tr>
<tr>
<td align="center">2</td>
<td align="center">0</td>
<td align="center">no</td>
</tr>
<tr>
<td align="center">3</td>
<td align="center">1</td>
<td align="center">yes</td>
</tr>
<tr>
<td align="center">4</td>
<td align="center">1</td>
<td align="center">yes if a majority exists on one side</td>
</tr>
<tr>
<td align="center">5</td>
<td align="center">2</td>
<td align="center">yes</td>
</tr>
<tr>
<td align="center">6</td>
<td align="center">2</td>
<td align="center">yes if a majority exists on one side</td>
</tr>
<tr>
<td align="center">7</td>
<td align="center">3</td>
<td align="center">yes</td>
</tr>
<tr>
<td align="center">8</td>
<td align="center">3</td>
<td align="center">yes if a majority exists on one side</td>
</tr>
<tr>
<td align="center">9</td>
<td align="center">4</td>
<td align="center">yes</td>
</tr>
</tbody>
</table>
<h3><a id="data-safety" class="anchor" href="#data-safety">Data Safety</a></h3>
<p>Streams replicate data across multiple nodes and publisher confirms are only
issued once the data has been replicated to a quorum of stream replicas.</p>
<p>Streams always store data on disk, however, they do not explicitly flush (fsync)
the data from the operating system page cache to the underlying storage
medium, instead they rely on the operating system to do as and when required.
This means that an uncontrolled shutdown of a server could result in data loss
for replicas hosted on that node. Although theoretically this opens up the possibility
of confirmed data loss, the chances of this happening during normal operation is
very small and the loss of data on a single node would typically just be re-replicated
from the other nodes in the system.</p>
<p>If more data safety is required then consider using quorum queues instead as no
publisher confirms are issued until at least a quorum of nodes have both written <em>and</em>
flushed the data to disk.</p>
<p><em><em>No guarantees are provided for messages that have not been confirmed using
the publisher confirm mechanism</em></em>. Such messages could be lost "mid-way", in an operating
system buffer or otherwise fail to reach the stream leader.</p>
<h3><a id="availability" class="anchor" href="#availability">Availability</a></h3>
<p>A stream should be able to tolerate a minority of stream replicas becoming unavailable
with no or little effect on availability.</p>
<p>Note that depending on the <a href="./partitions.html">partition handling strategy</a>
used RabbitMQ may restart itself during recovery and reset the node but as long as that
does not happen, this availability guarantee should hold true.</p>
<p>For example, a stream with three replicas can tolerate one node failure without losing availability.
A stream with five replicas can tolerate two, and so on.</p>
<p>If a quorum of nodes cannot be recovered (say if 2 out of 3 RabbitMQ nodes are
permanently lost) the queue is permanently unavailable and
will most likely need operator involvement to be recovered.</p>
<h2><a id="configuration" class="anchor" href="#configuration">Configuration</a></h2>
<p>For stream protocol port, TLS and other configuration, see the <a href="stream.html">Stream plugin guide</a>.</p>
<h2><a id="resource-use" class="anchor" href="#resource-use">Resource Use</a></h2>
<p>Streams usually will have lower CPU and memory footprint than quorum queues.</p>
<p>All data is stored on disk with only unwritten data stored in memory.</p>
<h2><a id="offset-tracking" class="anchor" href="#offset-tracking">Offset Tracking</a></h2>
<p>When using the broker provided offset tracking features (currently only available
when using the <a href="./stream.html">Stream plugin</a>) offsets are persisted in the stream
itself as non-message data. This means that as offset persistence is requested the
stream will grow on disk by some small amount per offset persistence request.</p>
<h2><a id="limitations" class="anchor" href="#limitations">Limitations</a></h2>
<h3><a id="limitations-message-encoding" class="anchor" href="#limitations-message-encoding">Message Encoding</a></h3>
<p>Streams internally store their messages as AMQP 1.0 encoded data. This means when
publishing using AMQP 0.9.1 a conversion takes place. Although the AMQP 1.0 data
model is mostly capable of containing all of AMQP 0.9.1's data model there are some
limitations. If an AMQP 0.9.1 message contains header entries with complex values
such as arrays or tables these headers will not be converted.
That is because headers are stored as application properties inside the AMQP 1.0 message and these can only
contain values of simple types, such as strings and numbers.</p>
<h3><a id="limitations-ui-metrics" class="anchor" href="#limitations-ui-metrics">UI Metric Accuracy</a></h3>
<p>Management UI can show a message count that slightly exceeds the actual count in the stream.
Due to the way stream storage is implemented, offset tracking information is also counted as messages, making the message count artificially larger than it is.
This should make no practical difference in most systems.</p><div id="help-and-feedback"><h2>Getting Help and Providing Feedback</h2><p>
                    If you have questions about the contents of this guide or
                    any other topic related to RabbitMQ, don't hesitate to ask them
                    on the <a href="https://groups.google.com/forum/#!forum/rabbitmq-users">RabbitMQ mailing list</a>.
                  </p></div><div id="contribute"><h2>Help Us Improve the Docs &lt;3</h2><p>
                    If you'd like to contribute an improvement to the site,
                    its source is <a href="https://github.com/rabbitmq/rabbitmq-website">available on GitHub</a>.
                    Simply fork the repository and submit a pull request. Thank you!
                  </p></div></div><div id="right-nav"><div id="in-this-section"><h4>In This Section</h4><ul>
     <li><a href="/admin-guide.html" class="selected">Server Documentation</a><ul>
       <li><a href="/configure.html">Configuration</a></li>
       <li><a href="/management.html">Management UI</a></li>
       <li><a href="/monitoring.html">Monitoring</a></li>
       <li><a href="/production-checklist.html">Production Checklist</a></li>
       <li><a href="/ssl.html">TLS Support</a></li>
       <li><a href="/streams.html" class="selected">Streams</a></li>
       <li><a href="/feature-flags.html">Feature Flags</a></li>
       <li><a href="/distributed.html">Distributed RabbitMQ</a></li>
       <li><a href="/clustering.html">Clustering</a></li>
       <li><a href="/reliability.html">Reliable Delivery</a></li>
       <li><a href="/definitions.html">Schema Definition Export and Import</a></li>
       <li><a href="/backup.html">Backup and restore</a></li>
       <li><a href="/alarms.html">Alarms</a></li>
       <li><a href="/memory-use.html">Memory Use</a></li>
       <li><a href="/networking.html">Networking</a></li>
       <li><a href="/vhosts.html">Virtual Hosts</a></li>
       <li><a href="/access-control.html">Access Control (Authorisation)</a></li>
       <li><a href="/authentication.html">Authentication Mechanisms</a></li>
       <li><a href="/ldap.html">LDAP</a></li>
       <li><a href="/lazy-queues.html">Lazy Queues</a></li>
       <li><a href="/event-exchange.html">Internal Event Exchange</a></li>
       <li><a href="/firehose.html">Firehose (Message Tracing)</a></li>
       <li><a href="/manpages.html">Manual Pages</a></li>
       <li><a href="/windows-quirks.html">Windows Quirks</a></li>
       
       
       
       
     </ul></li>
     <li><a href="/clients.html">Client Documentation</a></li>
     <li><a href="/plugins.html">Plugins</a></li>
     <li><a href="/news.html">News</a></li>
     <li><a href="/protocol.html">Protocol</a></li>
     <li><a href="/extensions.html">Our Extensions</a></li>
     <li><a href="/build.html">Building</a></li>
     
     <li><a href="/mpl.html">License</a></li>
   </ul></div></div></div><div class="clear"></div><div class="pageFooter"><div class="container"></div><div class="container"><div class="rabbit-logo"><a href="/"><img src="/img/logo-rabbitmq-white.svg" alt="RabbitMQ" /></a></div><ul class="footerNav"><li><a href="/#features">Features</a></li><li><a href="/#getstarted">Get Started</a></li><li><a href="/#support">Support</a></li><li><a href="/#community">Community</a></li><li><a href="/documentation.html">Docs</a></li></ul><p id="copyright">
          Copyright Â© 2007-2022 <a href="https://tanzu.vmware.com/">VMware</a>, Inc. or its affiliates. All rights reserved.
          <a href="https://www.vmware.com/help/legal.html">Terms of Use</a> â€¢
          <a href="https://www.vmware.com/help/privacy.html">Privacy</a> â€¢
          <a href="/trademark-guidelines.html">Trademark Guidelines</a> â€¢
          <a href="https://www.vmware.com/help/privacy/california-privacy-rights.html">Your California Privacy Rights</a> â€¢
          <a class="ot-sdk-show-settings">Cookie Settings</a><br /><a id="teconsent"></a></p></div></div></div><script type="text/javascript" src="/js/highlight.pack.js"></script><script type="text/javascript">
        // code highlighting
        window.addEventListener("load", function() {
          const selectors = "pre.lang-bash, \
                             pre.lang-csharp, \
                             pre.lang-elixir, \
                             pre.lang-erlang, \
                             pre.lang-go, \
                             pre.lang-groovy, \
                             pre.lang-haskell, \
                             pre.lang-html, \
                             pre.lang-ini, \
                             pre.lang-java, \
                             pre.lang-javascript, \
                             pre.lang-json, \
                             pre.lang-makefile, \
                             pre.lang-objectivec, \
                             pre.lang-php, \
                             pre.lang-plaintext, \
                             pre.lang-powershell, \
                             pre.lang-python, \
                             pre.lang-ruby, \
                             pre.lang-swift, \
                             pre.lang-yaml, \
                             pre.lang-xml";
          document.querySelectorAll(selectors).forEach(function(el) {
            hljs.highlightBlock(el);
          });
        });
      </script></body>
</html>
